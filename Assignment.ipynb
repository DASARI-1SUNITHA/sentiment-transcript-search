{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-Vg-TrBL3iu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H4y-U1Sv3Vw-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpora')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "zVrCmxld3u6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171f04b0-2fb1-4cf4-9dcb-d0f21ce0c85e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading corpora: Package 'corpora' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3rC7fBrYJ63i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscriptSearch:\n",
        "    def __init__(self, transcript_path):\n",
        "        self.transcript_path = transcript_path\n",
        "        self.chunks = self._preprocess_transcript()\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.chunks)\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.embeddings = self.embedding_model.encode(self.chunks)\n",
        "\n",
        "    def _preprocess_transcript(self):\n",
        "        \"\"\"Parse and clean the transcript into chunks\"\"\"\n",
        "        with open(self.transcript_path, 'r') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Split into timestamped segments\n",
        "        segments = re.findall(r'\\[.*?\\].*?(?=\\[|$)', content, re.DOTALL)\n",
        "\n",
        "        # Clean each segment\n",
        "        cleaned_chunks = []\n",
        "        for seg in segments:\n",
        "            # Remove timestamps\n",
        "            text = re.sub(r'\\[.*?\\]', '', seg).strip()\n",
        "            # Remove extra whitespace\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "            if text:\n",
        "                cleaned_chunks.append(text)\n",
        "\n",
        "        return cleaned_chunks\n",
        "\n",
        "    def keyword_search(self, question, top_k=3):\n",
        "        \"\"\"Basic keyword matching search\"\"\"\n",
        "        question = question.lower()\n",
        "        question_words = set(word_tokenize(question))\n",
        "\n",
        "        scores = []\n",
        "        for chunk in self.chunks:\n",
        "            chunk_words = set(word_tokenize(chunk.lower()))\n",
        "            # Count matching words (simple intersection)\n",
        "            score = len(question_words.intersection(chunk_words))\n",
        "            scores.append(score)\n",
        "\n",
        "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "        return [(self.chunks[i], scores[i]) for i in top_indices if scores[i] > 0]\n",
        "\n",
        "    def tfidf_search(self, question, top_k=3):\n",
        "        \"\"\"TF-IDF with cosine similarity search\"\"\"\n",
        "        question_vec = self.tfidf_vectorizer.transform([question])\n",
        "        similarities = cosine_similarity(question_vec, self.tfidf_matrix)\n",
        "        top_indices = np.argsort(similarities[0])[-top_k:][::-1]\n",
        "        return [(self.chunks[i], similarities[0][i]) for i in top_indices if similarities[0][i] > 0]\n",
        "\n",
        "    def semantic_search(self, question, top_k=3):\n",
        "        \"\"\"Embedding-based semantic search\"\"\"\n",
        "        question_embedding = self.embedding_model.encode([question])\n",
        "        similarities = cosine_similarity(question_embedding, self.embeddings)\n",
        "        top_indices = np.argsort(similarities[0])[-top_k:][::-1]\n",
        "        return [(self.chunks[i], similarities[0][i]) for i in top_indices if similarities[0][i] > 0.3]\n",
        "\n",
        "    def hybrid_search(self, question, top_k=3):\n",
        "        \"\"\"Combine results from all methods\"\"\"\n",
        "        keyword_results = self.keyword_search(question, top_k)\n",
        "        tfidf_results = self.tfidf_search(question, top_k)\n",
        "        semantic_results = self.semantic_search(question, top_k)\n",
        "          # Combine and deduplicate results\n",
        "        all_results = {}\n",
        "        for method, results in [('keyword', keyword_results),\n",
        "                              ('tfidf', tfidf_results),\n",
        "                              ('semantic', semantic_results)]:\n",
        "            for text, score in results:\n",
        "                if text not in all_results or score > all_results[text][1]:\n",
        "                    all_results[text] = (method, score)\n",
        "\n",
        "        # Sort by score\n",
        "        sorted_results = sorted(all_results.items(), key=lambda x: -x[1][1])\n",
        "        return [(text, f\"{method} (score: {score:.2f})\") for text, (method, score) in sorted_results[:top_k]]\n",
        "\n",
        "def main():\n",
        "    # Initialize with the transcript file\n",
        "    search = TranscriptSearch('New_Employee_Induction_transcript.txt')\n",
        "\n",
        "    print(\"Transcript Search System\")\n",
        "    print(\"Enter your question about employee induction (or 'quit' to exit):\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nQuestion: \").strip()\n",
        "        if question.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            print(\"Please enter a question.\")\n",
        "            continue\n",
        "\n",
        "        print(\"\\nSearch Results:\")\n",
        "\n",
        "        # Get hybrid results\n",
        "        results = search.hybrid_search(question)\n",
        "\n",
        "        if not results:\n",
        "            print(\"No relevant results found.\")\n",
        "            continue\n",
        "\n",
        "        for i, (text, method) in enumerate(results, 1):\n",
        "            print(f\"\\nResult {i} ({method}):\")\n",
        "            print(text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HKqOBjV4hGR",
        "outputId": "f1b532a3-de1d-4558-8228-996401816248"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcript Search System\n",
            "Enter your question about employee induction (or 'quit' to exit):\n",
            "\n",
            "Question: what is employee induction?\n",
            "\n",
            "Search Results:\n",
            "\n",
            "Result 1 (keyword (score: 4.00)):\n",
            "Beginning with the first topic, what is induction and what are the types of induction program?\n",
            "\n",
            "Result 2 (keyword (score: 3.00)):\n",
            "Employee induction is the program where the new employees introduce to the organization\n",
            "\n",
            "Result 3 (keyword (score: 3.00)):\n",
            "Don't forget to take the induction feedback for each new employee because this is helpful\n",
            "\n",
            "Question: 1\n",
            "\n",
            "Search Results:\n",
            "\n",
            "Result 1 (semantic (score: 0.37)):\n",
            "members.\n",
            "\n",
            "Question: what are the types of induction progrms?\n",
            "\n",
            "Search Results:\n",
            "\n",
            "Result 1 (keyword (score: 7.00)):\n",
            "Beginning with the first topic, what is induction and what are the types of induction program?\n",
            "\n",
            "Result 2 (keyword (score: 4.00)):\n",
            "Now let's see the types of induction process.\n",
            "\n",
            "Result 3 (keyword (score: 4.00)):\n",
            "Now moving on to the next part of the video that is what all topics are covered in the\n",
            "\n",
            "Question: what are the types of induction programs?\n",
            "\n",
            "Search Results:\n",
            "\n",
            "Result 1 (keyword (score: 7.00)):\n",
            "Beginning with the first topic, what is induction and what are the types of induction program?\n",
            "\n",
            "Result 2 (keyword (score: 4.00)):\n",
            "Now let's see the types of induction process.\n",
            "\n",
            "Result 3 (keyword (score: 4.00)):\n",
            "Now moving on to the next part of the video that is what all topics are covered in the\n",
            "\n",
            "Question: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgT_YsCt0fqr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}